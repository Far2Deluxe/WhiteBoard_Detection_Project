{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54282806",
   "metadata": {},
   "source": [
    "# Data Collection \n",
    "## Steps for collecting our data:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300e2a38",
   "metadata": {},
   "source": [
    " ## 1. üì∏ Lectures images:\n",
    " We have taken our data from the database of the study lectures along the previous four years , which was about 5000 image of whiteboards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa06723",
   "metadata": {},
   "source": [
    "## 2. Whiteboard Image Labeling with CVAT:\n",
    "\n",
    "This notebook provides a complete guide to labeling whiteboard images using the Computer Vision Annotation Tool (CVAT) on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd68437",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Before we begin, ensure you have the following installed:\n",
    "\n",
    "- Docker\n",
    "- Docker Compose\n",
    "- Git\n",
    "- Python 3.6+"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056a6d76",
   "metadata": {},
   "source": [
    "## 2.1 Setting Up CVAT Locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fcbac7",
   "metadata": {},
   "source": [
    "### 2.1.1 Install Docker and Docker Compose\n",
    "\n",
    "First, we need to install Docker on your local machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a32c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Ubuntu/Debian:\n",
    "!sudo apt update\n",
    "!sudo apt install docker.io\n",
    "!sudo systemctl start docker\n",
    "!sudo systemctl enable docker\n",
    "\n",
    "# Install Docker Compose\n",
    "!sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\n",
    "!sudo chmod +x /usr/local/bin/docker-compose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee98d9f7",
   "metadata": {},
   "source": [
    "### 2.1.2 Clone and Setup CVAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1aa9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the CVAT repository\n",
    "!git clone https://github.com/opencv/cvat\n",
    "%cd cvat\n",
    "\n",
    "# Start CVAT containers\n",
    "!docker-compose up -d\n",
    "\n",
    "# Create superuser for CVAT (follow prompts)\n",
    "!docker exec -it cvat bash -ic 'python3 ~/manage.py createsuperuser'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53037ee",
   "metadata": {},
   "source": [
    "CVAT will now be running at `http://localhost:8080`. You can log in with the credentials you just created."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae23a844",
   "metadata": {},
   "source": [
    "## 2.2 Preparing Your Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502e64e7",
   "metadata": {},
   "source": [
    "### 2.2.1 Organize Your Images\n",
    "\n",
    "Organize your whiteboard images in a directory structure like this:\n",
    "```\n",
    "whiteboard_data/\n",
    "‚îú‚îÄ‚îÄ image_001.jpg\n",
    "‚îú‚îÄ‚îÄ image_002.jpg\n",
    "‚îî‚îÄ‚îÄ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf89ef2",
   "metadata": {},
   "source": [
    "### 2.2.2 Verify Image Integrity\n",
    "\n",
    "Let's check our images before uploading (You can Skip the operation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f616848",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "def check_images(directory_path):\n",
    "    \"\"\"\n",
    "    Check all images in a directory for integrity and collect metadata\n",
    "    \"\"\"\n",
    "    image_info = []\n",
    "    corrupt_images = []\n",
    "    \n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            filepath = os.path.join(directory_path, filename)\n",
    "            try:\n",
    "                with Image.open(filepath) as img:\n",
    "                    width, height = img.size\n",
    "                    image_info.append({\n",
    "                        'filename': filename,\n",
    "                        'width': width,\n",
    "                        'height': height,\n",
    "                        'format': img.format,\n",
    "                        'mode': img.mode,\n",
    "                        'size_mb': os.path.getsize(filepath) / (1024 * 1024)\n",
    "                    })\n",
    "            except (IOError, OSError) as e:\n",
    "                corrupt_images.append(filename)\n",
    "                print(f\"Corrupt image: {filename} - {str(e)}\")\n",
    "    \n",
    "    return pd.DataFrame(image_info), corrupt_images\n",
    "\n",
    "# Specify your image directory\n",
    "image_dir = \"whiteboard_data\"\n",
    "image_df, corrupt_list = check_images(image_dir)\n",
    "\n",
    "print(f\"Total images: {len(image_df)}\")\n",
    "print(f\"Corrupt images: {len(corrupt_list)}\")\n",
    "image_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4165c11c",
   "metadata": {},
   "source": [
    "## 2.3 Creating a CVAT Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14681fbe",
   "metadata": {},
   "source": [
    "### 2.3.1 Define Label Schema\n",
    "\n",
    "First, we need to define what we're labeling on the whiteboards. Common labels might include:\n",
    "\n",
    "- Text\n",
    "- Diagrams\n",
    "- Mathematical equations\n",
    "- Tables\n",
    "- Drawings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09afff75",
   "metadata": {},
   "source": [
    "### 2.3.2 Create Project in CVAT UI\n",
    "\n",
    "1. Open `http://localhost:8080` in your browser\n",
    "2. Login with your credentials\n",
    "3. Click \"Create new project\"\n",
    "4. Name your project (e.g., \"Whiteboard Analysis\")\n",
    "5. Add labels with appropriate names and colors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b801818",
   "metadata": {},
   "source": [
    "## 2.4 Creating Tasks and Uploading Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcaa9027",
   "metadata": {},
   "source": [
    "### 2.4.1 Create Task in CVAT\n",
    "\n",
    "1. In your project, click \"Create new task\"\n",
    "2. Name your task (e.g., \"Whiteboard Batch 1\")\n",
    "3. Select your project\n",
    "4. Choose \"Shared\" if working with a team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c41d7",
   "metadata": {},
   "source": [
    "### 2.4.2 Upload Images\n",
    "\n",
    "You can upload images through the web interface or use the CVAT Python SDK or by simply just drag and drop into the local website."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a182a4ca",
   "metadata": {},
   "source": [
    "## 2.5 Annotation Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d756553",
   "metadata": {},
   "source": [
    "### 2.5.1 Using the CVAT Annotation Interface\n",
    "\n",
    "1. Open your task in CVAT\n",
    "2. Use the annotation tools:\n",
    "   - Rectangle: For bounding boxes around elements\n",
    "   - Polygon: For precise segmentation\n",
    "   - Points: For keypoint annotation\n",
    "   - Tag: For image-level labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400bfcbc",
   "metadata": {},
   "source": [
    "### 2.5.2 Keyboard Shortcuts\n",
    "\n",
    "Learn these essential shortcuts for efficient labeling:\n",
    "\n",
    "- `N` - Create a new shape\n",
    "- `M` - Change mode (move, reshape, etc.)\n",
    "- `F` - Move Forward to next Image.\n",
    "- `D` - Move Backward to previous Image.\n",
    "- `Tab` - Finish drawing a shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2a7aa7",
   "metadata": {},
   "source": [
    "### 2.5.3 Annotation Best Practices\n",
    "\n",
    "- Be consistent with your labeling approach\n",
    "- Use the same label for similar elements\n",
    "- Ensure bounding boxes fully contain objects\n",
    "- For overlapping objects, decide on a consistent approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2787770",
   "metadata": {},
   "source": [
    "## 2.6. Quality Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d118580",
   "metadata": {},
   "source": [
    "### 2.6.1 Review Process\n",
    "\n",
    "After completing annotations, it's important to review them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81e5b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_annotations(task_id):\n",
    "    \"\"\"\n",
    "    Analyze annotations for consistency and completeness\n",
    "    \"\"\"\n",
    "    with make_client(host=\"http://localhost:8080\", credentials=(\"username\", \"password\")) as client:\n",
    "        task = client.tasks.retrieve(task_id)\n",
    "        annotations = task.annotations\n",
    "        \n",
    "        # Get statistics\n",
    "        stats = {}\n",
    "        for label in task.labels:\n",
    "            stats[label.name] = 0\n",
    "        \n",
    "        for shape in annotations.shapes:\n",
    "            stats[shape.label] += 1\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# Get annotation statistics\n",
    "task_id = 1  # Replace with your task ID\n",
    "annotation_stats = analyze_annotations(task_id)\n",
    "print(\"Annotation Statistics:\")\n",
    "for label, count in annotation_stats.items():\n",
    "    print(f\"{label}: {count} instances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2a817",
   "metadata": {},
   "source": [
    "## 2.7 Exporting Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc826ade",
   "metadata": {},
   "source": [
    "### 2.7.1 Export Formats\n",
    "\n",
    "CVAT supports multiple export formats:\n",
    "- VOC XML\n",
    "- COCO JSON\n",
    "- YOLO\n",
    "- TFRecord\n",
    "- etc.\n",
    "\n",
    "\n",
    "#### Note that CVAT only supports YOLO 1.1 export meaning you can only export unrotated boxes and not polygons or any other shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4167e963",
   "metadata": {},
   "source": [
    "### 2.7.2 Export Through UI\n",
    "\n",
    "1. Open your task\n",
    "2. Click \"Menu\" ‚Üí \"Export task dataset\"\n",
    "3. Choose your preferred format\n",
    "4. Download the annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede810e",
   "metadata": {},
   "source": [
    "### 2.7.3 Export Programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a16dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_annotations(task_id, format_name=\"COCO 1.0\", output_path=\"annotations.json\"):\n",
    "    \"\"\"\n",
    "    Export annotations in specified format\n",
    "    \"\"\"\n",
    "    with make_client(host=\"http://localhost:8080\", credentials=(\"username\", \"password\")) as client:\n",
    "        task = client.tasks.retrieve(task_id)\n",
    "        \n",
    "        # Request export\n",
    "        task.export_dataset(format_name, filename=output_path, include_images=False)\n",
    "        \n",
    "        # Download exported file\n",
    "        task.download_export(output_path)\n",
    "        \n",
    "    print(f\"Annotations exported to {output_path}\")\n",
    "\n",
    "# Export annotations\n",
    "export_annotations(task_id=1, format_name=\"COCO 1.0\", output_path=\"whiteboard_annotations.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da8ff2c",
   "metadata": {},
   "source": [
    "## 2.8 Converting to Training Formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b325a7d8",
   "metadata": {},
   "source": [
    "### 2.8.1 Convert to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9dacb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def coco_to_yolo(coco_json_path, output_dir):\n",
    "    \"\"\"\n",
    "    Convert COCO format annotations to YOLO format\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok)\n",
    "    os.makedirs(os.path.join(output_dir, \"labels\"), exist_ok)\n",
    "    \n",
    "    # Load COCO data\n",
    "    with open(coco_json_path) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Create mapping from image id to image info\n",
    "    images = {img['id']: img for img in data['images']}\n",
    "    \n",
    "    # Create mapping from category id to category name\n",
    "    categories = {cat['id']: cat['name'] for cat in data['categories']}\n",
    "    \n",
    "    # Group annotations by image\n",
    "    annotations_by_image = {}\n",
    "    for ann in data['annotations']:\n",
    "        image_id = ann['image_id']\n",
    "        if image_id not in annotations_by_image:\n",
    "            annotations_by_image[image_id] = []\n",
    "        annotations_by_image[image_id].append(ann)\n",
    "    \n",
    "    # Process each image\n",
    "    for image_id, annotations in annotations_by_image.items():\n",
    "        image_info = images[image_id]\n",
    "        image_width = image_info['width']\n",
    "        image_height = image_info['height']\n",
    "        filename = image_info['file_name'].split('.')[0]  # Remove extension\n",
    "        \n",
    "        # Create YOLO format file\n",
    "        with open(os.path.join(output_dir, \"labels\", f\"{filename}.txt\"), \"w\") as f:\n",
    "            for ann in annotations:\n",
    "                category_id = ann['category_id']\n",
    "                category_name = categories[category_id]\n",
    "                \n",
    "                # Convert bbox from [x, y, width, height] to YOLO format [center_x, center_y, width, height] (normalized)\n",
    "                x, y, w, h = ann['bbox']\n",
    "                center_x = (x + w/2) / image_width\n",
    "                center_y = (y + h/2) / image_height\n",
    "                norm_w = w / image_width\n",
    "                norm_h = h / image_height\n",
    "                \n",
    "                # Write to file: class_id center_x center_y width height\n",
    "                f.write(f\"{category_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}\\n\")\n",
    "    \n",
    "    # Create classes file\n",
    "    with open(os.path.join(output_dir, \"classes.txt\"), \"w\") as f:\n",
    "        for cat_id, cat_name in sorted(categories.items()):\n",
    "            f.write(f\"{cat_name}\\n\")\n",
    "    \n",
    "    print(f\"YOLO format annotations saved to {output_dir}\")\n",
    "\n",
    "# Convert COCO to YOLO\n",
    "coco_to_yolo(\"whiteboard_annotations.json\", \"yolo_annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f347c3",
   "metadata": {},
   "source": [
    "# 3. üìä Load data with their labels:\n",
    "## YoloV8 data structure requirement:\n",
    "Yolo library detection training models require a simplified data structure as shown\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a0203",
   "metadata": {},
   "outputs": [],
   "source": [
    "whiteboard-Detection-Project/\n",
    "\n",
    "‚îú‚îÄ‚îÄ images/\n",
    "‚îÇ   ‚îú‚îÄ‚îÄ train/              # Conatins Train images\n",
    "‚îÇ   ‚îî‚îÄ‚îÄ val/            # Contains Validation Images\n",
    "‚îÇ             \n",
    "‚îú‚îÄ‚îÄ Labels/ \n",
    "    ‚îú‚îÄ‚îÄ train/          # Contains Labels or annotation data of train images (has same name of the images to be matched and understood by YOLO)    \n",
    "‚îÇ   ‚îî‚îÄ‚îÄ val/            # Contains Labels or annotation data of validiation images (has same name of the images to be matched and understood by YOLO)  \n",
    "‚îú‚îÄ‚îÄ conf.yaml               \n",
    "‚îî‚îÄ‚îÄ runs/               # Models which are trained are created here by YOLO at the end of training.\n",
    "\n",
    "\n",
    "\n",
    "Yolo requires the paths of the train and validaition folders which is given inside conf.yaml along side the class-id names (.i.e in our case 0:whiteboards)\n",
    "P.S\n",
    "The Train and val images should be divided as 80% Train and 20% Validiations for optimal training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef07d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contents of conf.yaml\n",
    "path: ./\n",
    "train: ./data/images/train\n",
    "val: ./data/images/val\n",
    "\n",
    "names:\n",
    "  0: Whiteboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb03936c",
   "metadata": {},
   "source": [
    "## ü§ñ Yolov8 Training Code:\n",
    "After having all the past steps setup, we can now run the training code provided below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3f1c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "\n",
    "print(ultralytics.__version__)\n",
    "\n",
    "model = YOLO(\"yolov8n.yaml\") \n",
    "model.train(data=\"conf.yaml\", epochs=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862aec43",
   "metadata": {},
   "source": [
    "The past code simply uses yolov8 nano to train the data with 100 epochs, which we had used to train our first model (This method uses CPU)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7768dcc",
   "metadata": {},
   "source": [
    "## üíØ Training Yolo on the GPU using CUDA\n",
    "Since Training on large data takes along time, using GPU for such processes could cut down the waiting time by much. This is the code we used:\n",
    "We also switched the model to YoloV8 Small version instead of nano which has more accuarcy yet takes longer time to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13773896",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# In order to navigate in project folder freely in code\n",
    "current_dir = Path(__file__).parent\n",
    "project_dir = current_dir.parent.parent\n",
    "yolo_models_dir = project_dir / \"src\" / \"data\"\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Ultralytics version:\", ultralytics.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "    # Load YOLO model\n",
    "    model = YOLO(project_dir / \"src\" / \"data\" / \"yolov8s.pt\")\n",
    "\n",
    "    # Train on GPU (device=0). Reduce workers to avoid multiprocessing issues.\n",
    "    model.train(\n",
    "        data= project_dir / \"conf.yaml\",\n",
    "        epochs=200,\n",
    "        device=0,\n",
    "        workers=0,   # <--- IMPORTANT for Windows\n",
    "        project = project_dir / \"src\" / \"models\" ,\n",
    "        name = \"Whiteboard Model\"\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714d010",
   "metadata": {},
   "source": [
    "## üìë Yolo Parameters we have used to train our latest model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99adfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import degrees\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "current_dir = Path(__file__).parent\n",
    "project_dir = current_dir.parent.parent\n",
    "yolo_models_dir = project_dir / \"src\" / \"data\"\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    ## Checks Version of Yolo and the availablity of CUDA for training Via GPU\n",
    "    print(\"Ultralytics version:\", ultralytics.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "    # Load YOLO model\n",
    "    model = YOLO(project_dir / \"src\" / \"data\" / \"yolov8s.pt\")\n",
    "\n",
    "    # Train on GPU (device=0). Reduce workers to avoid multiprocessing issues.\n",
    "    model.train(\n",
    "        data=\"conf.yaml\",\n",
    "        epochs=70,\n",
    "        device=0,\n",
    "        workers=0,\n",
    "        lr0=0.001,           # Initial learning rate\n",
    "        lrf=0.01,            # Final learning rate\n",
    "        degrees=3,          # Image rotation degrees\n",
    "        optimizer=\"AdamW\",   # Optimizer as string\n",
    "        patience=15,         # Early stopping patience\n",
    "        imgsz=640,           # Image size\n",
    "        batch=16,            # Batch size\n",
    "        project = project_dir / \"src\" / \"models\" ,\n",
    "        name = \"Whiteboard Model\",            \n",
    "        save=True,           # Save checkpoints\n",
    "        plots=True           # Generate training plots\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc5549",
   "metadata": {},
   "source": [
    "# Automatic Labeling Feature:\n",
    "\n",
    "We used an intelligent method to reduce the time and hardness of Labeling Process as follows:\n",
    "\n",
    "1. Train a preliminary model on a subset of your data\n",
    "2. Use it to pre-annotate the remaining images and save the images and their lables in a specfic folder named 'labeling_images' in \"results\" (i.e., .\\results\\labeling_images).\n",
    "3. Manually correct the annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff162995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path(__file__).parent\n",
    "project_dir = current_dir.parent.parent\n",
    "\n",
    "# Path to your trained model\n",
    "MODEL_PATH = project_dir / \"src\" / \"models\" / \"Whiteboard Model4\" / \"weights\" / \"best.pt\"   # replace with your path\n",
    "\n",
    "# Path to the folder containing images to label\n",
    "IMAGE_FOLDER = project_dir / \"src\" / \"data\" / \"image to label\"     # replace with your folder path\n",
    "\n",
    "# Path to the folder containing the labels files and images\n",
    "RESULTS_FOLDER = project_dir / \"results\"     # replace with your folder path\n",
    "\n",
    "# Confidence threshold for detection\n",
    "CONF_THRESHOLD = 0.5 \n",
    "\n",
    "\n",
    "\n",
    "def detect_whiteboards(input_dir, output_dir = RESULTS_FOLDER ):\n",
    "                    \n",
    "    # Load model\n",
    "    model = YOLO(MODEL_PATH)\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Run detection\n",
    "    results = model.predict(\n",
    "        source=input_dir,\n",
    "        conf=CONF_THRESHOLD,\n",
    "        save=True,\n",
    "        project=output_dir,\n",
    "        name='labeling_images',\n",
    "        exist_ok=True,\n",
    "        save_txt=True,\n",
    "        #save_conf=True,\n",
    "        #stream=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Detection complete! Results saved to: {output_dir}\")\n",
    "    return results\n",
    "\n",
    "# Usage\n",
    "detect_whiteboards(IMAGE_FOLDER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f6f9cd",
   "metadata": {},
   "source": [
    "## Find WhiteBoard images:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd349962",
   "metadata": {},
   "source": [
    "The following python script is about finding whiteboard images from any generic images and soring them to a specific folder named \"detected_images\" in \"results\" folder (i.e., .\\results\\detected_images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c55651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path(__file__).parent\n",
    "project_dir = current_dir.parent.parent\n",
    "\n",
    "# Path to your trained model\n",
    "MODEL_PATH = project_dir / \"src\" / \"models\" / \"Whiteboard Model4\" / \"weights\" / \"best.pt\"   # replace with your path\n",
    "\n",
    "# Path to the folder containing images to check\n",
    "IMAGE_FOLDER = project_dir / \"src\" / \"data\" / \"images to test\"     # replace with your folder path\n",
    "\n",
    "# Path to the folder containing the labels files and images\n",
    "RESULTS_FOLDER = project_dir / \"results\" / \"detected_images\"   # replace with your folder path\n",
    "\n",
    "# Confidence threshold for detection\n",
    "CONF_THRESHOLD = 0.5 \n",
    "\n",
    "\n",
    "# Load your custom trained model\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "os.makedirs(RESULTS_FOLDER, exist_ok=True)\n",
    "\n",
    "# Run inference on all images in the source directory\n",
    "results = model.predict(source=IMAGE_FOLDER, conf=CONF_THRESHOLD, save=False, stream=True)\n",
    "\n",
    "# Get class names from the model\n",
    "class_names = model.names\n",
    "# Find the class ID for 'Whiteboard' (replace with your actual class name if different)\n",
    "whiteboard_class_id = None\n",
    "for idx, name in class_names.items():\n",
    "    if name.lower() == 'whiteboard':\n",
    "        whiteboard_class_id = idx\n",
    "        break\n",
    "\n",
    "if whiteboard_class_id is None:\n",
    "    raise ValueError(\"Whiteboard class not found in model names.\")\n",
    "\n",
    "# Process results\n",
    "for result in results:\n",
    "    # Check if any detection is a whiteboard\n",
    "    detections = result.boxes\n",
    "    if detections is not None:\n",
    "        class_ids = detections.cls.int().tolist()\n",
    "        if whiteboard_class_id in class_ids:\n",
    "            # Get the image path\n",
    "            img_path = result.path\n",
    "            # Generate output path\n",
    "            output_path = os.path.join(RESULTS_FOLDER, os.path.basename(img_path))\n",
    "            # Save the image (original or annotated)\n",
    "            result.save(filename=output_path)  # Saves annotated image\n",
    "            # Alternatively, to save the original image without annotations:\n",
    "            # import shutil\n",
    "            # shutil.copy(img_path, output_path)\n",
    "            print(f\"Saved image with whiteboard: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034540fa",
   "metadata": {},
   "source": [
    "# YoloClassificationModelTest.py\n",
    "### This code uses classification models instead of detection models to sort the read a folder full of images and classifiy them, then move the classified photos into a whiteboard folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15213b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def classify_and_organize_whiteboards(\n",
    "    photos_folder, \n",
    "    model_path, \n",
    "    confidence_threshold=0.5,\n",
    "    create_whiteboard_folder=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Use a YOLO classification model to detect whiteboards in photos and organize them.\n",
    "    \n",
    "    Args:\n",
    "        photos_folder (str): Path to folder containing photos to test\n",
    "        model_path (str): Path to trained YOLO classification model (.pt file)\n",
    "        confidence_threshold (float): Minimum confidence to classify as whiteboard (0.0-1.0)\n",
    "        create_whiteboard_folder (bool): Whether to create a 'whiteboards' subfolder\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary statistics of the classification and organization\n",
    "    \"\"\"\n",
    "    # Convert to Path objects\n",
    "    photos_path = Path(photos_folder)\n",
    "    \n",
    "    # Check if photos folder exists\n",
    "    if not photos_path.exists():\n",
    "        raise FileNotFoundError(f\"Photos folder not found: {photos_folder}\")\n",
    "    \n",
    "    # Check if model file exists\n",
    "    if not Path(model_path).exists():\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    \n",
    "    # Load YOLO classification model\n",
    "    print(f\"üîÑ Loading YOLO classification model from: {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Create whiteboards folder if requested\n",
    "    whiteboards_folder = None\n",
    "    if create_whiteboard_folder:\n",
    "        whiteboards_folder = photos_path / \"whiteboards\"\n",
    "        whiteboards_folder.mkdir(exist_ok=True)\n",
    "        print(f\"üìÅ Created whiteboards folder: {whiteboards_folder}\")\n",
    "    \n",
    "    # Supported image extensions\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp'}\n",
    "    \n",
    "    # Find all image files\n",
    "    image_files = []\n",
    "    for file_path in photos_path.iterdir():\n",
    "        if file_path.is_file() and file_path.suffix.lower() in image_extensions:\n",
    "            image_files.append(file_path)\n",
    "    \n",
    "    print(f\"üîç Found {len(image_files)} image files to process\")\n",
    "    print(f\"üéØ Confidence threshold: {confidence_threshold}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Statistics\n",
    "    whiteboard_count = 0\n",
    "    non_whiteboard_count = 0\n",
    "    error_count = 0\n",
    "    whiteboard_files = []\n",
    "    non_whiteboard_files = []\n",
    "    error_files = []\n",
    "    \n",
    "    # Process each image\n",
    "    for i, image_file in enumerate(image_files, 1):\n",
    "        try:\n",
    "            print(f\"[{i}/{len(image_files)}] Processing: {image_file.name}\")\n",
    "            \n",
    "            # Run classification\n",
    "            results = model.predict(str(image_file), verbose=False)\n",
    "            \n",
    "            # Get prediction results\n",
    "            probs = results[0].probs.data.cpu().numpy()\n",
    "            class_names = results[0].names\n",
    "            predicted_class = class_names[probs.argmax()]\n",
    "            confidence = probs.max()\n",
    "            \n",
    "            print(f\"   üìä Prediction: {predicted_class} (confidence: {confidence:.3f})\")\n",
    "            \n",
    "            # Check if it's classified as whiteboard with sufficient confidence\n",
    "            is_whiteboard = (predicted_class.lower() in ['whiteboard', 'whiteboards', '0'] and \n",
    "                           confidence >= confidence_threshold)\n",
    "            \n",
    "            if is_whiteboard:\n",
    "                whiteboard_count += 1\n",
    "                whiteboard_files.append(image_file.name)\n",
    "                \n",
    "                if create_whiteboard_folder:\n",
    "                    # Move to whiteboards folder\n",
    "                    dest_path = whiteboards_folder / image_file.name\n",
    "                    shutil.move(str(image_file), str(dest_path))\n",
    "                    print(f\"   ‚úÖ WHITEBOARD DETECTED ‚Üí Moved to whiteboards folder\")\n",
    "                else:\n",
    "                    print(f\"   ‚úÖ WHITEBOARD DETECTED ‚Üí Keeping in place\")\n",
    "            else:\n",
    "                non_whiteboard_count += 1\n",
    "                non_whiteboard_files.append(image_file.name)\n",
    "                print(f\"   ‚ùå Not a whiteboard ‚Üí Keeping in place\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_count += 1\n",
    "            error_files.append(image_file.name)\n",
    "            print(f\"   ‚ö†Ô∏è  ERROR processing {image_file.name}: {str(e)}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä CLASSIFICATION SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"‚úÖ Whiteboards detected: {whiteboard_count}\")\n",
    "    print(f\"‚ùå Non-whiteboards: {non_whiteboard_count}\")\n",
    "    print(f\"‚ö†Ô∏è  Errors: {error_count}\")\n",
    "    print(f\"üìÅ Total processed: {len(image_files)}\")\n",
    "    \n",
    "    if create_whiteboard_folder and whiteboard_count > 0:\n",
    "        print(f\"üìÇ Whiteboards moved to: {whiteboards_folder}\")\n",
    "    \n",
    "    # Show some examples\n",
    "    if whiteboard_files:\n",
    "        print(f\"\\nüéØ Sample whiteboard files detected:\")\n",
    "        for file in whiteboard_files[:5]:  # Show first 5\n",
    "            print(f\"   ‚Ä¢ {file}\")\n",
    "        if len(whiteboard_files) > 5:\n",
    "            print(f\"   ... and {len(whiteboard_files) - 5} more\")\n",
    "    \n",
    "    return {\n",
    "        \"total_images\": len(image_files),\n",
    "        \"whiteboard_count\": whiteboard_count,\n",
    "        \"non_whiteboard_count\": non_whiteboard_count,\n",
    "        \"error_count\": error_count,\n",
    "        \"whiteboard_files\": whiteboard_files,\n",
    "        \"non_whiteboard_files\": non_whiteboard_files,\n",
    "        \"error_files\": error_files,\n",
    "        \"whiteboards_folder\": str(whiteboards_folder) if create_whiteboard_folder else None\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the whiteboard classification and organization.\"\"\"\n",
    "    \n",
    "    # Configuration - MODIFY THESE PATHS AS NEEDED\n",
    "    photos_folder = \"test3\"  # Folder with photos to test\n",
    "    model_path = \"src/models/Whiteboard Model Classification5/weights/best.pt\"  # Path to your trained model\n",
    "    \n",
    "    # Optional: You can also try other model paths if the above doesn't exist\n",
    "    alternative_models = [\n",
    "        \"src/models/Whiteboard Model Classification2/weights/best.pt\",\n",
    "        \"src/models/Whiteboard Model Classification3/weights/best.pt\",\n",
    "        \"yolov8n-cls.pt\"  # Pre-trained model as fallback\n",
    "    ]\n",
    "    \n",
    "    # Check if primary model exists, try alternatives if not\n",
    "    if not Path(model_path).exists():\n",
    "        print(f\"‚ö†Ô∏è  Primary model not found: {model_path}\")\n",
    "        print(\"üîç Trying alternative models...\")\n",
    "        \n",
    "        for alt_model in alternative_models:\n",
    "            if Path(alt_model).exists():\n",
    "                model_path = alt_model\n",
    "                print(f\"‚úÖ Using alternative model: {model_path}\")\n",
    "                break\n",
    "        else:\n",
    "            print(\"‚ùå No suitable model found!\")\n",
    "            return\n",
    "    \n",
    "    # Configuration parameters\n",
    "    confidence_threshold = 0.6  # Adjust this value (0.0-1.0) - higher = more strict\n",
    "    create_whiteboard_folder = True  # Set to False if you don't want to move files\n",
    "    \n",
    "    print(\"üöÄ Starting YOLO Whiteboard Classification and Organization\")\n",
    "    print(f\"üìÅ Photos folder: {photos_folder}\")\n",
    "    print(f\"ü§ñ Model: {model_path}\")\n",
    "    print(f\"üéØ Confidence threshold: {confidence_threshold}\")\n",
    "    print(f\"üìÇ Create whiteboard folder: {create_whiteboard_folder}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    try:\n",
    "        results = classify_and_organize_whiteboards(\n",
    "            photos_folder=photos_folder,\n",
    "            model_path=model_path,\n",
    "            confidence_threshold=confidence_threshold,\n",
    "            create_whiteboard_folder=create_whiteboard_folder\n",
    "        )\n",
    "        \n",
    "        # Final success message\n",
    "        if results[\"whiteboard_count\"] > 0:\n",
    "            print(f\"\\nüéâ SUCCESS! Found and organized {results['whiteboard_count']} whiteboard images!\")\n",
    "        else:\n",
    "            print(f\"\\nüìù No whiteboards detected with confidence >= {confidence_threshold}\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a9085a",
   "metadata": {},
   "source": [
    "# Labels-Converter.py\n",
    "### A tool that helped in turning polygon annotations into simple boxes by approximating or estimating a box that covers the maximum x and y cooridnates of the polygon edges. This helped in annotating some small datasets that came with polygon annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b2e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Paths\n",
    "labels_dir = \"./Polygon_Labels\"   # folder with your current polygon labels\n",
    "output_dir = \"./Box_Labels\"      # folder for converted box labels\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for file in os.listdir(labels_dir):\n",
    "    if not file.endswith(\".txt\"):\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(labels_dir, file)\n",
    "    output_path = os.path.join(output_dir, file)\n",
    "\n",
    "    with open(input_path, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    new_lines = []\n",
    "    for line in lines:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) <= 5:\n",
    "            # Already a box label\n",
    "            new_lines.append(line.strip())\n",
    "            continue\n",
    "\n",
    "        cls = parts[0]\n",
    "        coords = list(map(float, parts[1:]))\n",
    "\n",
    "        # Split into x,y pairs\n",
    "        xs = coords[0::2]\n",
    "        ys = coords[1::2]\n",
    "\n",
    "        # Bounding box\n",
    "        xmin, xmax = min(xs), max(xs)\n",
    "        ymin, ymax = min(ys), max(ys)\n",
    "\n",
    "        # Convert to YOLO box format\n",
    "        x_center = (xmin + xmax) / 2\n",
    "        y_center = (ymin + ymax) / 2\n",
    "        width = xmax - xmin\n",
    "        height = ymax - ymin\n",
    "\n",
    "        new_line = f\"{cls} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
    "        new_lines.append(new_line)\n",
    "\n",
    "    # Save new file\n",
    "    with open(output_path, \"w\") as f:\n",
    "        f.write(\"\\n\".join(new_lines))\n",
    "\n",
    "print(\"‚úÖ Conversion complete! Box labels saved in:\", output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8ec87",
   "metadata": {},
   "source": [
    "# Labels and Images matching.py\n",
    "### This code allowed for pulling of label files with same name of images from another folder, this helped when manual selection of and moving of labels was tedious in the process of data oragnizing for YOLO training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c35a26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def move_matching_text_files(images_folder, labels_folder):\n",
    "    \"\"\"\n",
    "    Find all image files in the images folder, then search for matching text files\n",
    "    in the labels folder and move them to the images folder.\n",
    "    \n",
    "    Supported image formats: .jpg, .jpeg, .png, .bmp, .tiff\n",
    "    Text files should have the same base name as the image files.\n",
    "    \n",
    "    Args:\n",
    "        images_folder (str): Path to folder containing image files\n",
    "        labels_folder (str): Path to folder containing text label files\n",
    "    \n",
    "    Returns:\n",
    "        dict: Summary of the operation with counts and file lists\n",
    "    \"\"\"\n",
    "    # Convert to Path objects for easier handling\n",
    "    images_path = Path(images_folder)\n",
    "    labels_path = Path(labels_folder)\n",
    "    \n",
    "    # Check if folders exist\n",
    "    if not images_path.exists():\n",
    "        raise FileNotFoundError(f\"Images folder not found: {images_folder}\")\n",
    "    if not labels_path.exists():\n",
    "        raise FileNotFoundError(f\"Labels folder not found: {labels_folder}\")\n",
    "    \n",
    "    # Supported image extensions\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif'}\n",
    "    \n",
    "    # Find all image files\n",
    "    image_files = []\n",
    "    for file_path in images_path.iterdir():\n",
    "        if file_path.is_file() and file_path.suffix.lower() in image_extensions:\n",
    "            image_files.append(file_path)\n",
    "    \n",
    "    print(f\"üîç Found {len(image_files)} image files in {images_folder}\")\n",
    "    \n",
    "    # Statistics\n",
    "    moved_count = 0\n",
    "    not_found_count = 0\n",
    "    already_exists_count = 0\n",
    "    moved_files = []\n",
    "    not_found_files = []\n",
    "    \n",
    "    # Process each image file\n",
    "    for image_file in image_files:\n",
    "        # Get the base name without extension\n",
    "        base_name = image_file.stem\n",
    "        \n",
    "        # Try multiple naming patterns for text files\n",
    "        text_file = None\n",
    "        \n",
    "        # First try: exact match (Images (1234).txt)\n",
    "        text_file = labels_path / f\"{base_name}.txt\"\n",
    "        \n",
    "        # Second try: convert \"Images (1234)\" -> \"Image (1234)\"\n",
    "        if not text_file.exists() and base_name.startswith(\"Images (\"):\n",
    "            text_base_name = base_name.replace(\"Images (\", \"Image (\", 1)\n",
    "            text_file = labels_path / f\"{text_base_name}.txt\"\n",
    "            \n",
    "        # Third try: convert \"Image (1234)\" -> \"Images (1234)\" (reverse)\n",
    "        if not text_file.exists() and base_name.startswith(\"Image (\"):\n",
    "            text_base_name = base_name.replace(\"Image (\", \"Images (\", 1)\n",
    "            text_file = labels_path / f\"{text_base_name}.txt\"\n",
    "        \n",
    "        if text_file.exists():\n",
    "            # Check if text file already exists in images folder\n",
    "            dest_text_file = images_path / f\"{base_name}.txt\"\n",
    "            \n",
    "            if dest_text_file.exists():\n",
    "                print(f\"‚ö†Ô∏è  Text file already exists: {base_name}.txt\")\n",
    "                already_exists_count += 1\n",
    "            else:\n",
    "                # Move the text file to images folder\n",
    "                shutil.move(str(text_file), str(dest_text_file))\n",
    "                moved_count += 1\n",
    "                moved_files.append(base_name)\n",
    "                print(f\"‚úÖ Moved: {base_name}.txt\")\n",
    "        else:\n",
    "            print(f\"‚ùå No text file found for: {image_file.name}\")\n",
    "            not_found_count += 1\n",
    "            not_found_files.append(image_file.name)\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\nüìä Summary:\")\n",
    "    print(f\"   ‚úÖ Moved: {moved_count} text files\")\n",
    "    print(f\"   ‚ö†Ô∏è  Already existed: {already_exists_count} text files\")\n",
    "    print(f\"   ‚ùå Not found: {not_found_count} text files\")\n",
    "    print(f\"   üìÅ Total images processed: {len(image_files)}\")\n",
    "    \n",
    "    return {\n",
    "        \"moved_count\": moved_count,\n",
    "        \"already_exists_count\": already_exists_count,\n",
    "        \"not_found_count\": not_found_count,\n",
    "        \"total_images\": len(image_files),\n",
    "        \"moved_files\": moved_files,\n",
    "        \"not_found_files\": not_found_files\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run the text file moving operation.\"\"\"\n",
    "    # Define the folders\n",
    "    images_folder = \"data/images/temp vald\"\n",
    "    labels_folder = \"data/images/temp vald labels\"\n",
    "    \n",
    "    print(\"üöÄ Starting text file matching and moving process...\")\n",
    "    print(f\"üìÅ Images folder: {images_folder}\")\n",
    "    print(f\"üìÅ Labels folder: {labels_folder}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        results = move_matching_text_files(images_folder, labels_folder)\n",
    "        \n",
    "        if results[\"moved_count\"] > 0:\n",
    "            print(f\"\\nüéâ Successfully moved {results['moved_count']} text files!\")\n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è  No text files were moved.\")\n",
    "            \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Unexpected error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
